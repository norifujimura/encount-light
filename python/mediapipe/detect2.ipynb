{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67924a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "class Part:\n",
    "    def __init__(self,):\n",
    "        self.isExist = False\n",
    "        self.pos=(0,0)\n",
    "        self.world_pos=(0,0,0)\n",
    "        self.color  = (255,255,255)\n",
    "\n",
    "    def init(self,point,world_point,width,height,color):\n",
    "        self.pos = (int(point[0]*width),int(point[1]*height))\n",
    "        self.world_pos = world_point\n",
    "        self.color = color\n",
    "        self.isExist = True\n",
    "\n",
    "class Bound:\n",
    "    x=0\n",
    "    y=0\n",
    "    w=0\n",
    "    h=0\n",
    "    \n",
    "class Head:\n",
    "    def __init__(self,):\n",
    "        self.isExist = False\n",
    "        self.pos=(0,0)\n",
    "        self.world_pos=(0,0,0)\n",
    "        self.color  = (255,127,127)\n",
    "        \n",
    "        self.head_width = 0\n",
    "        self.heading = 0\n",
    "        self.eye_length = 200\n",
    "        self.eye_pos=(0,0)\n",
    "\n",
    "    def init(self,nose,lear,rear,color):\n",
    "        #head width in real size\n",
    "        r_w_pos = rear.world_pos\n",
    "        l_w_pos = lear.world_pos\n",
    "        a=np.array([r_w_pos[0],r_w_pos[1],r_w_pos[2]])\n",
    "        b=np.array([l_w_pos[0],l_w_pos[1],l_w_pos[2]])\n",
    "        self.head_width=np.linalg.norm(b-a)\n",
    "        \n",
    "        self.world_pos = (\n",
    "            (r_w_pos[0]+l_w_pos[0])/2.0,\n",
    "            (r_w_pos[1]+l_w_pos[1])/2.0,\n",
    "            (r_w_pos[2]+l_w_pos[2])/2.0\n",
    "        )\n",
    "        \n",
    "        #2D screen pos\n",
    "        r_pos = rear.pos\n",
    "        l_pos = lear.pos\n",
    "        pos = (\n",
    "            (r_pos[0]+l_pos[0])/2.0,\n",
    "            (r_pos[1]+l_pos[1])/2.0\n",
    "        )\n",
    "        self.pos = (int(pos[0]),int(pos[1]))\n",
    "        \n",
    "        #print(\"Head x:\"+str(self.pos[0])+\" y:\"+str(self.pos[1]))\n",
    "        self.color = color\n",
    "        self.isExist = True\n",
    "        \n",
    "        '''\n",
    "        #culc heading on x-z plane\n",
    "        center_pos = (self.world_pos[0],self.world_pos[2])\n",
    "        nose_pos = (nose.world_pos[0],nose.world_pos[2])\n",
    "        '''\n",
    "        \n",
    "        #culc heading by 2D\n",
    "        center_pos = self.pos\n",
    "        nose_pos = nose.pos\n",
    "        \n",
    "        a = np.array([center_pos[0], center_pos[1]])\n",
    "        b = np.array([nose_pos[0], nose_pos[1]])\n",
    "        vec = b - a\n",
    "        self.heading = -1 * math.degrees(np.arctan2(vec[0], vec[1])) +90\n",
    "        \n",
    "        #culc eye line\n",
    "        radians = math.radians(self.heading)\n",
    "\n",
    "        eye_x = self.pos[0]+int(np.cos(radians)*self.eye_length)\n",
    "        eye_y = self.pos[1]+int(np.sin(radians)*self.eye_length)\n",
    "        self.eye_pos = (eye_x,eye_y)\n",
    "        \n",
    "        \n",
    "        \n",
    "class Body:\n",
    "    def __init__(self,id,landmarks,world_landmarks,visibility_threshold,width,height):\n",
    "        self.id = id\n",
    "        self.landmarks = landmarks\n",
    "        self.world_landmarks = world_landmarks\n",
    "        self.visibility_threshold = visibility_threshold\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.bound = Bound()\n",
    "    \n",
    "        # for landmark in person:\n",
    "\n",
    "        self.nose=Part()\n",
    "        self.leye=Part()\n",
    "        self.reye=Part()\n",
    "        self.lear=Part()\n",
    "        self.rear=Part()\n",
    "        self.lshoulder=Part()\n",
    "        self.rshoulder=Part()\n",
    "        self.lelbow = Part()\n",
    "        self.relbow = Part()\n",
    "        self.lhand = Part()\n",
    "        self.rhand = Part()\n",
    "        self.lhip = Part()\n",
    "        self.rhip = Part()\n",
    "        self.lknee = Part()\n",
    "        self.rknee = Part()\n",
    "        self.lfoot = Part()\n",
    "        self.rfoot = Part()\n",
    "        #parts = [nose,leye,reye,lear,rear,lshoulder,rshoulder,lelbow,relbow,lhand,rhand,lhip,rhip,lknee,rknee,lfoot,rfoot]\n",
    "        self.parts = [self.nose,self.leye,self.reye,self.lear,self.rear,self.lshoulder,self.rshoulder]\n",
    "\n",
    "        self.head_width = 0\n",
    "        self.head = Head()\n",
    "\n",
    "        self.eye_length= 200\n",
    "\n",
    "    \n",
    "    def process(self):\n",
    "        nose_color = (0,0,255)\n",
    "        eye_color = (127,127,255)\n",
    "        left_color = (255,127,127)\n",
    "        right_color = (127,255,127)\n",
    "        \n",
    "        '''\n",
    "        for idx, landmark in enumerate(pose_landmarks_proto.landmark):\n",
    "            #landmark_px = _normalized_to_pixel_coordinates(landmark.x, landmark.y,width, height)\n",
    "        '''\n",
    "        \n",
    "        # print(\"idx:\"+str(idx)+\" x:\"+str(pose_landmarks[0].x))\n",
    "        \n",
    "        # Draw the pose landmarks.\n",
    "        #for i in range(len(self.landmarks)):\n",
    "        i = 0;\n",
    "        for landmark in self.landmarks:\n",
    "            #point = self.landmarks[i]\n",
    "            #world_point = self.world_landmarks[i]\n",
    "            point = (landmark.x,landmark.y)\n",
    "            world_point = (0,0,0)\n",
    "            width = self.width\n",
    "            height = self.height\n",
    "            \n",
    "            \n",
    "            \n",
    "            #print(\"Visibility:\"+str(point.visibility))\n",
    "            \n",
    "            #if point.visibility >= self.visibility_threshold:\n",
    "            #nose\n",
    "            if(i==0): \n",
    "                self.parts[0].init(point,world_point,width,height,nose_color)\n",
    "                #print(\"i:\"+str(i)+\" x:\"+str(point[0]))\n",
    "            #l-eye\n",
    "            if(i==2): \n",
    "                self.parts[1].init(point,world_point,width,height,eye_color)\n",
    "            #r-eye\n",
    "            if(i==5): \n",
    "                self.parts[2].init(point,world_point,width,height,eye_color)\n",
    "            #l-ear\n",
    "            if(i==7): \n",
    "                self.parts[3].init(point,world_point,width,height,left_color)\n",
    "            #r-ear\n",
    "            if(i==8): \n",
    "                self.parts[4].init(point,world_point,width,height,right_color)\n",
    "            #l-shoulder\n",
    "            if(i==11): \n",
    "                self.parts[5].init(point,world_point,width,height,left_color)\n",
    "            #r-shoulder\n",
    "            if(i==12): \n",
    "                self.parts[6].init(point,world_point,width,height,right_color)\n",
    "                '''\n",
    "            #l-elbow\n",
    "            if(i==13): \n",
    "                self.parts[7].init(point,world_point,width,height,left_color)\n",
    "            #r-elbow\n",
    "            if(i==14): \n",
    "                self.parts[8].init(point,world_point,width,height,right_color)\n",
    "            #l-hand\n",
    "            if(i==15): \n",
    "                self.parts[9].init(point,world_point,width,height,left_color)\n",
    "            #r-hand\n",
    "            if(i==16): \n",
    "                self.parts[10].init(point,world_point,width,height,right_color)\n",
    "            #l-hip\n",
    "            if(i==23): \n",
    "                self.parts[11].init(point,world_point,width,height,left_color)\n",
    "            #r-hip\n",
    "            if(i==24): \n",
    "                self.parts[12].init(point,world_point,width,height,right_color)\n",
    "            #l-knee\n",
    "            if(i==25): \n",
    "                self.parts[13].init(point,world_point,width,height,left_color)\n",
    "            #r-knee\n",
    "            if(i==26): \n",
    "                self.parts[14].init(point,world_point,width,height,right_color)\n",
    "            #l-foot\n",
    "            if(i==27): \n",
    "                self.parts[15].init(point,world_point,width,height,left_color)\n",
    "            #r-foot\n",
    "            if(i==28): \n",
    "                self.parts[16].init(point,world_point,width,height,right_color)\n",
    "                '''\n",
    "            i = i+1\n",
    "            \n",
    "        #culc bound box\n",
    "        minx = 10000\n",
    "        miny = 10000\n",
    "        maxx = 0\n",
    "        maxy = 0\n",
    "        for part in self.parts:\n",
    "            if(part.isExist):\n",
    "                x = part.pos[0]\n",
    "                y = part.pos[1]\n",
    "                if maxx<x:\n",
    "                    maxx = x\n",
    "                if maxy<y:\n",
    "                    maxy = y\n",
    "                if x<minx:\n",
    "                    minx = x\n",
    "                if y<miny:\n",
    "                    miny = y\n",
    "        self.bound.x = minx\n",
    "        self.bound.y = miny\n",
    "        self.bound.w = maxx-minx\n",
    "        self.bound.h = maxy-miny\n",
    "        \n",
    "        #culc head and headings\n",
    "        if self.nose.isExist and self.lear.isExist and self.rear.isExist:\n",
    "            #print(\"head\")\n",
    "            self.head.init(self.nose,self.lear,self.rear,(255,255,255))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "759bf55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "ERROR: Unable to read from webcam. Please verify your webcam settings.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m ERROR: Unable to read from webcam. Please verify your webcam settings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nori/.pyenv/versions/3.9.16/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "\n",
    "#from body import Body\n",
    "\n",
    "\n",
    "#1 do inference \n",
    "#2 convert the results to the list of Body objects\n",
    "# https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/python#video\n",
    "def process_bodies(\n",
    "    result:vision.PoseLandmarkerResult,\n",
    "    width:int,\n",
    "    height:int,\n",
    "    visibility_threshold: float = 0.8\n",
    ")-> List[Body]:\n",
    "    \n",
    "    '''\n",
    "    for pose_landmarks in persons.pose_landmarks:\n",
    "    # Draw the pose landmarks.\n",
    "    pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "    pose_landmarks_proto.landmark.extend([\n",
    "        landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y,\n",
    "                                        z=landmark.z) for landmark\n",
    "        in pose_landmarks\n",
    "    ])\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        pose_landmarks_proto,\n",
    "        mp_pose.POSE_CONNECTIONS,\n",
    "        mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "        '''\n",
    "\n",
    "    # https://github.com/googlesamples/mediapipe/blob/main/examples/pose_landmarker/python/%5BMediaPipe_Python_Tasks%5D_Pose_Landmarker.ipynb\n",
    "    bodies = []\n",
    "    \n",
    "    #print(str(len(result.pose_landmarks)))\n",
    "    \n",
    "    pose_landmarks_list = persons.pose_landmarks\n",
    "    \n",
    "      # Loop through the detected poses to visualize.\n",
    "    for idx in range(len(pose_landmarks_list)):\n",
    "        pose_landmarks = pose_landmarks_list[idx]\n",
    "        \n",
    "        #print(\"idx:\"+str(idx)+\" x:\"+str(pose_landmarks[0].x))\n",
    "\n",
    "        '''\n",
    "        # Draw the pose landmarks.\n",
    "        pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        pose_landmarks_proto.landmark.extend([\n",
    "          landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in pose_landmarks\n",
    "        ])\n",
    "        '''\n",
    "        \n",
    "        #print(type(pose_landmarks_proto))\n",
    "        #pose_landmarks_proto is  mediapipe.framework.formats.landmark_pb2.NormalizedLandmarkList\n",
    "        \n",
    "        \n",
    "        body = Body(idx,pose_landmarks,(0,0,0),visibility_threshold,width,height)\n",
    "        body.process()\n",
    "        #print(\"body head:\"+str(body.head.pos[0]))\n",
    "        bodies.append(body) \n",
    "    \n",
    "    '''\n",
    "    #for landmarks in result.pose_landmarks:\n",
    "    for id in range(len(result.pose_landmarks)):\n",
    "        # print(type(person))\n",
    "        print(\"id:\"+str(id))\n",
    "        landmarks = result.pose_landmarks[id]\n",
    "        world_landmarks = result.pose_world_landmarks[id]\n",
    "\n",
    "        #key points\n",
    "        body = Body(landmarks,world_landmarks,visibility_threshold,width,height)\n",
    "        body.process()\n",
    "        bodies.append(body)  \n",
    "    return bodies\n",
    "    '''\n",
    "    return bodies\n",
    "\n",
    "def draw_bodies(\n",
    "    image: np.ndarray,\n",
    "    list_bodies: List[Body],\n",
    ") -> np.ndarray:\n",
    "    body_index = 0\n",
    "    for body in list_bodies:\n",
    "        #body\n",
    "        \n",
    "        for part in body.parts:\n",
    "            if(part.isExist):\n",
    "                cv2.circle(image, part.pos, 10, part.color, thickness=-1)\n",
    "            \n",
    "        cv2.rectangle(image,(body.bound.x,body.bound.y),(body.bound.x+body.bound.w,body.bound.y+body.bound.h), (255, 255, 255), 1)\n",
    "        #head\n",
    "        \n",
    "        head = body.head\n",
    "        \n",
    "        cv2.circle(image, head.pos, 50, head.color, thickness=1)\n",
    "        head_width_text = '{:.2f}'.format(head.head_width)\n",
    "        cv2.putText(image, head_width_text, head.pos, cv2.FONT_HERSHEY_PLAIN,\n",
    "                2, head.color, 1)\n",
    "        \n",
    "        #heading\n",
    "        cv2.arrowedLine(image, head.pos, head.eye_pos, head.color, thickness=2)\n",
    "        #print(\"body:\"+str(body_index)+\" head x:\"+str(head.pos[0]))\n",
    "        body_index = body_index+1\n",
    "        \n",
    "    return image\n",
    "\n",
    "def draw_bodies_5(\n",
    "    image: np.ndarray,\n",
    ") -> np.ndarray:\n",
    "    body_index = 0\n",
    "    for body in bodies:\n",
    "        #body\n",
    "        \n",
    "        for part in body.parts:\n",
    "            if(part.isExist):\n",
    "                cv2.circle(image, part.pos, 10, part.color, thickness=-1)\n",
    "            \n",
    "        cv2.rectangle(image,(body.bound.x,body.bound.y),(body.bound.x+body.bound.w,body.bound.y+body.bound.h), (255, 255, 255), 1)\n",
    "        #head\n",
    "        \n",
    "        head = body.head\n",
    "        \n",
    "        cv2.circle(image, head.pos, 50, head.color, thickness=1)\n",
    "        head_width_text = '{:.2f}'.format(head.head_width)\n",
    "        cv2.putText(image, head_width_text, head.pos, cv2.FONT_HERSHEY_PLAIN,\n",
    "                2, (255,255,255), 1)\n",
    "        \n",
    "        #heading\n",
    "        cv2.arrowedLine(image, head.pos, head.eye_pos, (255, 255, 255), thickness=2)\n",
    "        #print(\"body:\"+str(body_index)+\" head x:\"+str(head.pos[0]))\n",
    "        body_index = body_index+1\n",
    "        \n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_bodies_2(image: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    if persons:\n",
    "    # Draw landmarks.\n",
    "        for pose_landmarks in persons.pose_landmarks:\n",
    "            # Draw the pose landmarks.\n",
    "            pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "            pose_landmarks_proto.landmark.extend([\n",
    "                landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y,\n",
    "                                                z=landmark.z) for landmark\n",
    "                in pose_landmarks\n",
    "            ])\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image,\n",
    "                pose_landmarks_proto,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_bodies_3(image: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    if persons:\n",
    "    # Draw landmarks.\n",
    "        for person in persons.pose_landmarks:\n",
    "            # Draw the pose landmarks.\n",
    "            for landmark in person:\n",
    "                 #print(type(landmark))\n",
    "                pos = (int(landmark.x*width),int(landmark.y*height))\n",
    "                # landmark: https://developers.google.com/mediapipe/api/solutions/java/com/google/mediapipe/tasks/components/containers/Landmark\n",
    "                cv2.circle(image,pos, 5, (0,0,255), thickness=-1)\n",
    "                #print(landmark.x)\n",
    "    return image\n",
    "\n",
    "def draw_bodies_4(image: np.ndarray,result:vision.PoseLandmarkerResult\n",
    ") -> np.ndarray:\n",
    "    if result:\n",
    "    # Draw landmarks.\n",
    "        for person in result.pose_landmarks:\n",
    "            # Draw the pose landmarks.\n",
    "            for landmark in person:\n",
    "                 #print(type(landmark))\n",
    "                pos = (int(landmark.x*width),int(landmark.y*height))\n",
    "                # landmark: https://developers.google.com/mediapipe/api/solutions/java/com/google/mediapipe/tasks/components/containers/Landmark\n",
    "                cv2.circle(image,pos, 5, (0,0,255), thickness=-1)\n",
    "                #print(landmark.x)\n",
    "    return image\n",
    "\n",
    "\n",
    "# draw in x-z plane\n",
    "\n",
    "def draw_bodies_world(image: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    if DETECTION_RESULT:\n",
    "        ratio = 100\n",
    "    # Draw landmarks.\n",
    "        for person in DETECTION_RESULT.pose_world_landmarks:\n",
    "            # Draw the pose landmarks.\n",
    "            for landmark in person:\n",
    "                 #print(type(landmark))\n",
    "                pos = (int(landmark.x*ratio),int(landmark.y*ratio))\n",
    "                # landmark: https://developers.google.com/mediapipe/api/solutions/java/com/google/mediapipe/tasks/components/containers/Landmark\n",
    "                cv2.circle(image,pos, 5, (255,0,255), thickness=-1)\n",
    "                #print(landmark.x)\n",
    "    return image\n",
    "\n",
    "def draw_segments(image: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    if (output_segmentation_masks and DETECTION_RESULT):\n",
    "        if DETECTION_RESULT.segmentation_masks is not None:\n",
    "            segmentation_mask = DETECTION_RESULT.segmentation_masks[0].numpy_view()\n",
    "            mask_image = np.zeros(image.shape, dtype=np.uint8)\n",
    "            mask_image[:] = mask_color\n",
    "            condition = np.stack((segmentation_mask,) * 3, axis=-1) > 0.1\n",
    "            visualized_mask = np.where(condition, mask_image, image)\n",
    "            image= cv2.addWeighted(image, overlay_alpha,\n",
    "                                            visualized_mask, overlay_alpha,\n",
    "                                            0)\n",
    "    return image\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "# Global variables to calculate FPS\n",
    "#COUNTER, FPS = 0, 0\n",
    "#START_TIME = time.time()\n",
    "#DETECTION_RESULT = None\n",
    "persons = None\n",
    "bodies = []\n",
    "\n",
    "\"\"\"Continuously run inference on images acquired from the camera.\n",
    "\n",
    "Args:\n",
    "  model: Name of the pose landmarker model bundle.\n",
    "  num_poses: Max number of poses that can be detected by the landmarker.\n",
    "  min_pose_detection_confidence: The minimum confidence score for pose\n",
    "    detection to be considered successful.\n",
    "  min_pose_presence_confidence: The minimum confidence score of pose\n",
    "    presence score in the pose landmark detection.\n",
    "  min_tracking_confidence: The minimum confidence score for the pose\n",
    "    tracking to be considered successful.\n",
    "  output_segmentation_masks: Choose whether to visualize the segmentation\n",
    "    mask or not.\n",
    "  camera_id: The camera id to be passed to OpenCV.\n",
    "  width: The width of the frame captured from the camera.\n",
    "  height: The height of the frame captured from the camera.\n",
    "\"\"\"\n",
    "    \n",
    "#camera_id = 1 # 1 for webcam on Mac\n",
    "camera_id = \"video0.mp4\" # 1 for webcam on Mac\n",
    "width = 1280 #1280 for webcam for mac\n",
    "height= 720 # 720 for Webcam for mac\n",
    "\n",
    "model = 'pose_landmarker_lite.task'\n",
    "num_poses = 4\n",
    "min_pose_detection_confidence = 0.5\n",
    "min_pose_presence_confidence = 0.5\n",
    "min_tracking_confidence = 0.9\n",
    "output_segmentation_masks = False\n",
    "\n",
    "fps = 0\n",
    "end_time = 0\n",
    "start_time = 0\n",
    "isUpdated = False\n",
    "\n",
    "\n",
    "# Start capturing video input from the camera\n",
    "cap = cv2.VideoCapture(camera_id)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "image = np.zeros((height, width,3), np.uint8)\n",
    "cv2.putText(image, \"hello\", (10, 30),\n",
    "               cv2.FONT_HERSHEY_PLAIN, 1.5,\n",
    "               (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "cv2.startWindowThread()\n",
    "cv2.imshow(model, image)\n",
    "\n",
    "'''\n",
    "# Visualization parameters\n",
    "row_size = 50  # pixels\n",
    "left_margin = 24  # pixels\n",
    "text_color = (0, 0, 0)  # black\n",
    "font_size = 1\n",
    "font_thickness = 1\n",
    "fps_avg_frame_count = 10\n",
    "overlay_alpha = 0.5\n",
    "mask_color = (100, 100, 0)  # cyan\n",
    "'''\n",
    "\n",
    "def callback_result(result: vision.PoseLandmarkerResult,\n",
    "                unused_output_image: mp.Image, timestamp_ms: int):\n",
    "    global persons,bodies,width,height,fps,end_time,start_time,isUpdated\n",
    "    persons = result\n",
    "    \n",
    "    end_time = time.time()\n",
    "    time_diff = end_time - start_time #sec\n",
    "    fps = 1.0 / time_diff\n",
    "        \n",
    "    start_time = time.time()\n",
    "    \n",
    "    bodies = process_bodies(persons,width,height,0.5)\n",
    "    isUpdated = True\n",
    "    \n",
    "    \n",
    "    # print(type(result))\n",
    "    '''\n",
    "    # Calculate the FPS\n",
    "    if COUNTER % fps_avg_frame_count == 0:\n",
    "        FPS = fps_avg_frame_count / (time.time() - START_TIME)\n",
    "        START_TIME = time.time()\n",
    "\n",
    "    DETECTION_RESULT = result\n",
    "    COUNTER += 1\n",
    "    '''\n",
    "    \n",
    "# Initialize the pose landmarker model\n",
    "base_options = python.BaseOptions(model_asset_path=model)\n",
    "options = vision.PoseLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    running_mode=vision.RunningMode.LIVE_STREAM,\n",
    "    num_poses=num_poses,\n",
    "    min_pose_detection_confidence=min_pose_detection_confidence,\n",
    "    min_pose_presence_confidence=min_pose_presence_confidence,\n",
    "    min_tracking_confidence=min_tracking_confidence,\n",
    "    output_segmentation_masks=output_segmentation_masks,\n",
    "    result_callback=callback_result)\n",
    "detector = vision.PoseLandmarker.create_from_options(options)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Continuously capture images from the camera and run inference\n",
    "while cap.isOpened():\n",
    "\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        sys.exit(\n",
    "            'ERROR: Unable to read from webcam. Please verify your webcam settings.'\n",
    "        )\n",
    "\n",
    "    image = cv2.flip(image, 1)\n",
    "\n",
    "    # Convert the image from BGR to RGB as required by the TFLite model.\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_image)\n",
    "\n",
    "    # Run pose landmarker using the model.\n",
    "    if isUpdated==False:\n",
    "        detector.detect_async(mp_image, time.time_ns() // 1_000_000)\n",
    "    \n",
    "    current_frame = image\n",
    "    \n",
    "    if persons:\n",
    "        #bodies = process_bodies(persons,width,height,0.5)\n",
    "        current_frame = draw_bodies(current_frame,bodies)\n",
    "        #current_frame = draw_bodies_2(current_frame)\n",
    "        #current_frame = draw_segments(current_frame)\n",
    "    \n",
    "    #current_frame = draw_bodies(current_frame)\n",
    "    \n",
    "    #current_frame = draw_bodies_world(current_frame)\n",
    "    \n",
    "    \n",
    "    # Show the FPS\n",
    "    #fps_text = 'FPS = ' + str(int(fps))\n",
    "    fps_text = 'FPS = {:.1f}'.format(fps)\n",
    "    text_location = (10,40)\n",
    "    cv2.putText(current_frame, fps_text, text_location, cv2.FONT_HERSHEY_PLAIN,\n",
    "                2, (255,255,255), 1)\n",
    "\n",
    "    if isUpdated:\n",
    "        cv2.imshow(model, current_frame)\n",
    "        isUpdated = False\n",
    "\n",
    "    time.sleep(0.01)\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    if key == ord('q'):            #qを押した時の処理\n",
    "        cv2.waitKey(1)\n",
    "        cv2.destroyAllWindows()  \n",
    "        cap.release()\n",
    "        cv2.waitKey(1)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52316ac",
   "metadata": {},
   "source": [
    "これを見るとデータの仕様がわかる　https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/python\n",
    "\n",
    "The output contains the following world coordinates (WorldLandmarks):\n",
    "\n",
    "x, y, and z: Real-world 3-dimensional coordinates in meters, with the midpoint of the hips as the origin.\n",
    "\n",
    "visibility: The likelihood of the landmark being visible within the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bb9d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad9dc7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e6f1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
